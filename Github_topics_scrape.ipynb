{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe2149bd",
   "metadata": {},
   "source": [
    "# Scraping top Repositories for Github Topics from https://github.com/topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18241be4",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae9e92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "header = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 11.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36 Edge/18.19582'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e028c55",
   "metadata": {},
   "source": [
    "### Parse through Beautiful Soup object to find Top Github Topics, Topic Desciption and URL of Topic Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7537ec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape topic titles\n",
    "def get_topic_title(soup):\n",
    "    top_tit = []\n",
    "    topic_title_tag = soup.find_all(\n",
    "        \"p\", class_=\"f3 lh-condensed mb-0 mt-1 Link--primary\")\n",
    "    for title in topic_title_tag:\n",
    "        top_tit.append(title.text)\n",
    "    return top_tit\n",
    "\n",
    "\n",
    "# Function to scrape description of each topic\n",
    "def get_topic_desc(soup):\n",
    "    top_desc = []\n",
    "    topic_tag_desc = soup.find_all(\"p\", class_=\"f5 color-fg-muted mb-0 mt-1\")\n",
    "    for desc in topic_tag_desc:\n",
    "        top_desc.append(desc.text.strip())\n",
    "    return top_desc\n",
    "\n",
    "\n",
    "# Function to scarpe url of each topic page\n",
    "def get_topic_url(soup):\n",
    "    top_url = []\n",
    "    topic_tag_url = soup.find_all(\n",
    "        class_=\"no-underline flex-1 d-flex flex-column\")\n",
    "    for url in topic_tag_url:\n",
    "        top_url.append(\"https://github.com\"+url[\"href\"])\n",
    "    return top_url\n",
    "\n",
    "\n",
    "# Function to combine scraped data, return data frame and convert it into csv file\n",
    "def get_topics():\n",
    "    github_topics_url = \"https://github.com/topics\"\n",
    "    data = requests.get(github_topics_url, headers=header)\n",
    "    if data.status_code != 200:\n",
    "        raise Exception(f\"Failed to load page {github_topics_url}\")\n",
    "    soup = BeautifulSoup(data.text, \"html.parser\")\n",
    "    dict_topics = {\n",
    "        \"Topic Title\": get_topic_title(soup),\n",
    "        \"Topic Desciption\": get_topic_desc(soup),\n",
    "        \"Topic URL\": get_topic_url(soup)\n",
    "    }\n",
    "    git_topics_df=pd.DataFrame(dict_topics)\n",
    "    git_topics_df.to_csv(\"Github Topics.csv\", index=False) \n",
    "    return git_topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a97b6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2625f82a",
   "metadata": {},
   "source": [
    "### Get Information about top repositories of each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3200c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to ocnvert stars from string to integer\n",
    "def convert_star_to_int(repo_stars):\n",
    "    star_list = []\n",
    "    for star in repo_stars:\n",
    "        if (star.text.strip()[-1] == \"k\"):\n",
    "            star_list.append(int(float(star.text.strip()[:-1])*1000))\n",
    "        else:\n",
    "            star_list.append(int(star.text.strip()[:-1]))\n",
    "    return star_list\n",
    "\n",
    "\n",
    "# Function to get information of each repo\n",
    "def get_repo_info(topic_repo, repo_stars):\n",
    "    repo_dict = {\n",
    "        \"Username\": [],\n",
    "        \"Repository Name\": [],\n",
    "        \"Repository Stars\": [],\n",
    "        \"Repository URL\": []\n",
    "    }\n",
    "    for repo in topic_repo:\n",
    "        repo_dict[\"Username\"].append(repo.find_all(\"a\")[0].text.strip())\n",
    "    for repo in topic_repo:\n",
    "        repo_dict[\"Repository Name\"].append(repo.find_all(\"a\")[1].text.strip())\n",
    "    for repo in topic_repo:\n",
    "        repo_dict[\"Repository URL\"].append(\n",
    "            \"https://github.com\"+repo.find_all(\"a\")[1][\"href\"])\n",
    "    repo_dict[\"Repository Stars\"] = (convert_star_to_int(repo_stars))[:]\n",
    "    return repo_dict\n",
    "\n",
    "\n",
    "# Function to combine scraped data, return data frame and convert it into csv file\n",
    "def get_topics_repo(topic_url, path):\n",
    "    # Download page from URL\n",
    "    data_topic = requests.get(topic_url, headers=header)\n",
    "    # Check status code\n",
    "    if data_topic.status_code != 200:\n",
    "        raise Exception(f\"Failed to load page {topic_url}\")\n",
    "    # Parse using beautiful soup\n",
    "    soup_topic = BeautifulSoup(data_topic.text, \"html.parser\")\n",
    "    topic_repo = soup_topic.find_all(\n",
    "        \"h3\", class_=\"f3 color-fg-muted text-normal lh-condensed\")\n",
    "    repo_stars = soup_topic.find_all(\"span\", class_=\"Counter js-social-count\")\n",
    "    # Return dataframe\n",
    "    repo_dict = get_repo_info(topic_repo, repo_stars)\n",
    "    repo_df = pd.DataFrame(repo_dict)\n",
    "    repo_df.to_csv(path, index=False)\n",
    "    return repo_df\n",
    "    \n",
    "\n",
    "# Function to scrape repo data for each topic\n",
    "def scrape_topics():\n",
    "    git_topics_df = get_topics()\n",
    "    os.makedirs(\"Data\", exist_ok=True)\n",
    "    for index, row in git_topics_df.iterrows():\n",
    "        if os.path.exists(f\"Data/{row['Topic Title']}.csv\"):\n",
    "            print(f\"Data/{row['Topic Title']}.csv already exists.\\nSkipping\")\n",
    "        else:\n",
    "            print(f\"Scraping top repositories for {row['Topic Title']}\")\n",
    "            get_topics_repo(row[\"Topic URL\"], f\"Data/{row['Topic Title']}.csv\")\n",
    "\n",
    "\n",
    "scrape_topics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
